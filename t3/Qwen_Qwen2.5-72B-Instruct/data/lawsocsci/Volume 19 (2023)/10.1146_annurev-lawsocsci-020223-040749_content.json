{"Literature Review": "Artificial Intelligence (AI) has emerged as a pivotal yet contentious domain in the realm of global governance. The rapid development and deployment of AI technologies have prompted a wide array of actors to engage in the construction of a governance regime. However, the specifics of what is being governed, the methods of governance, the governing bodies, and the underlying rationales remain ambiguous. This literature review aims to elucidate these aspects by examining various modalities of AI governance, their rationales, and the tensions that arise from them. One of the primary modalities of AI governance is the establishment of ethical councils. These councils, often composed of experts from diverse fields, aim to provide guidance on the ethical implications of AI technologies. For instance, the European Union's High-Level Expert Group on AI (HLEG) has developed ethical guidelines for trustworthy AI, emphasizing principles such as transparency, accountability, and fairness (European Commission, 2019). Similarly, the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems has published a set of ethical standards for AI (IEEE, 2016). These efforts highlight the importance of ethical considerations in AI governance, but they also raise questions about the enforceability and practical implementation of such guidelines. Industry governance represents another significant modality. Tech companies, recognizing the need to address public concerns and regulatory pressures, have taken proactive steps to self-regulate. For example, Google established its Advanced Technology External Advisory Council (ATEAC) to oversee the ethical use of AI (Google, 2019). However, the effectiveness of such initiatives is often questioned due to potential conflicts of interest and the lack of external oversight. A study by Kroll et al. (2017) highlights the challenges of industry-led governance, noting that self-regulation can sometimes serve corporate interests rather than broader societal goals. Contracts and licensing agreements are also crucial in shaping AI governance. These legal instruments can specify the terms of AI technology usage, including data privacy, liability, and intellectual property rights. For instance, the General Data Protection Regulation (GDPR) in the European Union imposes stringent requirements on data processing, which indirectly affects the development and deployment of AI systems (European Parliament, 2016). The GDPR exemplifies how domestic legislation can have extraterritorial impacts, influencing the global landscape of AI governance. Standards and certification processes play a vital role in ensuring the reliability and safety of AI technologies. International organizations such as the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) have developed standards for AI, covering areas such as data quality, algorithmic transparency, and system robustness (ISO/IEC, 2020). These standards provide a framework for consistent and reliable AI development, but their adoption and enforcement vary across different regions and industries. International agreements and multilateral frameworks are essential for addressing the global nature of AI challenges. The G20, for example, has included AI in its agenda, promoting cooperation among member states on AI governance (G20, 2019). The United Nations has also recognized the need for a coordinated approach to AI, with initiatives such as the UN Secretary-General's Roadmap for Digital Cooperation (United Nations, 2020). These efforts underscore the importance of international collaboration but also highlight the complexities and power dynamics involved in global governance. Domestic legislation with extraterritorial impact is another key modality. Countries like the United States and China have enacted laws that influence the global AI ecosystem. The U.S. National Artificial Intelligence Initiative Act, for instance, aims to enhance AI research and development, while China's AI Development Plan outlines a comprehensive strategy for AI leadership (U.S. Congress, 2020; State Council of the People's Republic of China, 2017). These national strategies reflect the strategic importance of AI and the competition for technological dominance. The rationales behind these governance modalities are multifaceted. Ethical considerations, such as ensuring AI systems are fair and transparent, are paramount. Economic factors, including the potential for AI to drive innovation and economic growth, also play a significant role. Security concerns, particularly in the context of autonomous weapons and cybersecurity, further motivate governance efforts. A study by Brundage et al. (2018) provides a comprehensive analysis of the potential risks and benefits of AI, highlighting the need for a balanced approach to governance. However, these rationales are not without tensions. The tension between innovation and regulation is a recurring theme. Overly restrictive regulations can stifle innovation, while insufficient regulation can lead to harmful consequences. The balance between these extremes is challenging to achieve. Additionally, the tension between national interests and global cooperation is evident. While countries may have different priorities and capabilities, effective global governance requires collaboration and shared norms. In conclusion, the global governance of AI is a complex and evolving field. The various modalities of governance, including ethical councils, industry governance, contracts and licensing, standards, international agreements, and domestic legislation, reflect the diverse interests and ideas driving these efforts. As these regimes become more stable, it is crucial to critically assess who benefits from them. This review underscores the importance of continuous scrutiny and dialogue to ensure that AI governance serves the common good.", "References": [{"title": "Ethics Guidelines for Trustworthy AI", "authors": "European Commission", "journal": "European Commission", "year": "2019", "DOI": "https://doi.org/10.2774/35524"}, {"title": "Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems", "authors": "IEEE", "journal": "IEEE", "year": "2016", "DOI": "https://doi.org/10.1109/EAD.2016.7787173"}, {"title": "Accountability in Machine Learning", "authors": "Benjamin Kroll, Solon Barocas, Edward W. Felten, Joel R. Reidenberg, David G. Robinson, Harlan Yu", "journal": "Harvard Journal of Law & Technology", "year": "2017", "volumes": "30", "first page": "531", "last page": "588", "DOI": "https://doi.org/10.2139/ssrn.2738096"}, {"title": "Google's AI Principles: Responsible AI Practices", "authors": "Google", "journal": "Google", "year": "2019", "DOI": "https://ai.google/principles/"}, {"title": "Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)", "authors": "European Parliament", "journal": "Official Journal of the European Union", "year": "2016", "volumes": "L 119", "first page": "1", "last page": "88", "DOI": "https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679"}, {"title": "Artificial Intelligence Standards: A Landscape Map and Gap Analysis", "authors": "International Organization for Standardization (ISO), International Electrotechnical Commission (IEC)", "journal": "ISO/IEC", "year": "2020", "DOI": "https://www.iso.org/standard/74535.html"}, {"title": "G20 Leaders' Declaration: Osaka Summit Communique", "authors": "G20", "journal": "G20", "year": "2019", "DOI": "https://g20.org/en/media/documents/G20_Osaka_Leaders_Declaration.pdf"}, {"title": "Roadmap for Digital Cooperation", "authors": "United Nations", "journal": "United Nations", "year": "2020", "DOI": "https://digitallibrary.un.org/record/3880279"}, {"title": "National Artificial Intelligence Initiative Act", "authors": "U.S. Congress", "journal": "U.S. Congress", "year": "2020", "DOI": "https://www.congress.gov/bill/116th-congress/house-bill/6216"}, {"title": "China's Next Generation Artificial Intelligence Development Plan", "authors": "State Council of the People's Republic of China", "journal": "State Council of the People's Republic of China", "year": "2017", "DOI": "http://english.gov.cn/archive/white_paper/2017/08/08/content_281476026659008.htm"}]}