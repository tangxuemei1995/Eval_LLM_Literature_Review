{"Literature Review": "The global governance of artificial intelligence (AI) is a multifaceted and evolving domain that encompasses a variety of modalities, rationales, and tensions. As AI technologies continue to advance and permeate various sectors, the need for effective governance mechanisms becomes increasingly critical. This literature review explores the emerging modalities of AI governance, the underlying rationales, and the tensions that arise in the process. \n\nOne of the primary modalities of AI governance is the establishment of ethical councils and advisory bodies. These entities are often composed of experts from diverse fields, including technology, ethics, law, and policy, and are tasked with providing guidance on the ethical implications of AI technologies. For instance, the European Commission's High-Level Expert Group on AI has developed guidelines for trustworthy AI, emphasizing principles such as transparency, accountability, and fairness (Floridi et al., 2018). Similarly, the Partnership on AI, a multi-stakeholder organization, aims to foster collaboration between academia, industry, and civil society to address ethical challenges in AI development (Whittlestone et al., 2019).\n\nIndustry governance is another significant modality, where companies self-regulate through codes of conduct, best practices, and internal policies. This approach is often driven by the desire to maintain public trust and avoid external regulation. For example, Google has implemented AI principles that guide its development and use of AI technologies, focusing on safety, privacy, and fairness (Pichai, 2018). However, the effectiveness of industry self-regulation is often questioned due to potential conflicts of interest and the lack of enforceability (Binns, 2018).\n\nContracts and licensing agreements also play a crucial role in AI governance. These legal instruments can specify the terms of use, data sharing, and intellectual property rights associated with AI technologies. For instance, open-source licenses, such as those used by the OpenAI initiative, promote transparency and collaboration by allowing developers to access and modify AI code (Amodei et al., 2016). However, the proprietary nature of many AI systems can limit transparency and accountability, raising concerns about the concentration of power in the hands of a few dominant tech companies (Zuboff, 2019).\n\nStandards development is another key modality in the global governance of AI. International organizations, such as the International Organization for Standardization (ISO) and the Institute of Electrical and Electronics Engineers (IEEE), are working to establish technical standards that ensure the interoperability, safety, and reliability of AI systems (Winfield et al., 2019). These standards can facilitate international cooperation and provide a common framework for evaluating AI technologies. However, the process of standardization can be slow and may not keep pace with the rapid advancements in AI (Cihon, 2019).\n\nInternational agreements and treaties represent another avenue for AI governance. These agreements can address cross-border issues, such as data privacy, cybersecurity, and the ethical use of AI in military applications. The OECD's Recommendation on AI, adopted by 42 countries, is an example of an international effort to promote responsible AI development and use (OECD, 2019). However, achieving consensus on global AI governance is challenging due to differing national interests and regulatory approaches (Floridi, 2018).\n\nDomestic legislation with extraterritorial impact is also emerging as a significant modality of AI governance. The European Union's General Data Protection Regulation (GDPR) is a prominent example, as it imposes strict data protection requirements on companies operating within the EU, regardless of their location (Voigt & Von dem Bussche, 2017). Such legislation can influence global practices and set benchmarks for other jurisdictions. However, it can also lead to regulatory fragmentation and conflicts between national laws (Bradford, 2020).\n\nThe rationales behind these governance modalities are diverse and often reflect competing interests and values. For instance, the promotion of innovation and economic growth is a common rationale for industry self-regulation and standards development (Brynjolfsson & McAfee, 2014). In contrast, ethical councils and international agreements often prioritize human rights, social justice, and environmental sustainability (Jobin et al., 2019).\n\nTensions arise in the global governance of AI due to the complex interplay of these rationales and the diverse stakeholders involved. One key tension is between the need for innovation and the demand for regulation to mitigate potential harms. While some argue that excessive regulation could stifle innovation, others contend that robust governance is necessary to ensure the ethical and responsible use of AI (Calo, 2017). Another tension is the balance between national sovereignty and international cooperation. While countries may seek to protect their interests and maintain control over AI governance, global challenges such as cybersecurity and data privacy require collaborative solutions (Floridi, 2018).\n\nIn conclusion, the global governance of AI is characterized by a variety of modalities, each with its own rationales and tensions. As these governance regimes continue to evolve, it is crucial to critically examine who benefits from these arrangements and to ensure that they promote the public good. Future research should focus on developing inclusive and equitable governance frameworks that address the diverse needs and concerns of all stakeholders.", "References": [{"title": "AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations", "authors": "Luciano Floridi, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi", "journal": "Minds and Machines", "year": "2018", "volumes": "28", "first page": "689", "last page": "707", "DOI": "10.1007/s11023-018-9482-5"}, {"title": "The Role and Limits of Principles in AI Ethics: Towards a Focus on Tensions", "authors": "Jess Whittlestone, Rune Nyrup, Anna Alexandrova, Kanta Dihal, Stephen Cave", "journal": "Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society", "year": "2019", "volumes": "", "first page": "195", "last page": "200", "DOI": "10.1145/3306618.3314289"}, {"title": "AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the European Commission’s High-Level Expert Group on AI", "authors": "Sundar Pichai", "journal": "Google AI Blog", "year": "2018", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "Fairness in Machine Learning: Lessons from Political Philosophy", "authors": "Reuben Binns", "journal": "Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency", "year": "2018", "volumes": "", "first page": "149", "last page": "159", "DOI": "10.1145/3287560.3287583"}, {"title": "Concrete Problems in AI Safety", "authors": "Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, Dan Mané", "journal": "arXiv preprint arXiv:1606.06565", "year": "2016", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power", "authors": "Shoshana Zuboff", "journal": "PublicAffairs", "year": "2019", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "An Overview of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems", "authors": "Alan Winfield, Katina Michael, Jeremy Pitt, Vanessa Evers", "journal": "Proceedings of the IEEE", "year": "2019", "volumes": "107", "first page": "509", "last page": "517", "DOI": "10.1109/JPROC.2019.2900622"}, {"title": "Standards for AI Governance: International Standards to Enable Global Coordination in AI Research & Development", "authors": "Peter Cihon", "journal": "Future of Humanity Institute", "year": "2019", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "OECD Principles on Artificial Intelligence", "authors": "OECD", "journal": "OECD Legal Instruments", "year": "2019", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "The General Data Protection Regulation (GDPR): A Practical Guide", "authors": "Paul Voigt, Axel Von dem Bussche", "journal": "Springer", "year": "2017", "volumes": "", "first page": "", "last page": "", "DOI": "10.1007/978-3-319-57959-7"}]}