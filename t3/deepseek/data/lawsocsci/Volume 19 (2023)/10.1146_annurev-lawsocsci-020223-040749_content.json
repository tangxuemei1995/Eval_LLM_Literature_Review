{"Literature Review": "The advent of artificial intelligence (AI) has ushered in a new era of technological innovation, with profound implications for global governance. As AI technologies become increasingly integrated into various sectors, the need for a coherent and effective governance framework has become paramount. This literature review explores the modalities, rationales, and tensions inherent in the global governance of AI, drawing on a diverse body of scholarly work. The governance of AI is characterized by a multiplicity of actors, including states, international organizations, corporations, and civil society, each bringing their own interests and perspectives to the table. Ethical councils have emerged as one modality of governance, aiming to address the moral and societal implications of AI. These councils often grapple with questions of bias, privacy, and accountability, seeking to establish ethical guidelines for AI development and deployment (Floridi et al., 2018). Industry governance represents another significant modality, with tech giants playing a pivotal role in shaping the regulatory landscape. Through self-regulation and the establishment of industry standards, these corporations aim to balance innovation with ethical considerations (Cath, 2018). Contracts and licensing agreements also serve as governance tools, enabling the control and oversight of AI technologies. These legal instruments can stipulate the terms of use, data handling practices, and compliance requirements, thereby influencing the behavior of AI developers and users (Zarsky, 2016). Standards, both technical and ethical, are crucial in ensuring the interoperability and safety of AI systems. International standards organizations, such as the International Organization for Standardization (ISO), have been active in developing guidelines for AI (Winfield & Jirotka, 2018). International agreements, such as treaties and conventions, provide a framework for cross-border cooperation on AI governance. These agreements can address issues such as data sharing, cybersecurity, and the ethical use of AI in military applications (Brundage et al., 2020). Domestic legislation with extraterritorial impact is another important modality, as national laws can influence global AI practices. For instance, the European Union's General Data Protection Regulation (GDPR) has set a benchmark for data privacy worldwide (Veale & Zuiderveen Borgesius, 2018). The rationales underpinning these governance modalities are diverse, ranging from the promotion of innovation and economic growth to the protection of human rights and societal values. However, these rationales are often in tension with one another, reflecting the competing interests of different stakeholders. For example, the drive for technological advancement may clash with the need to safeguard privacy and prevent discrimination (Eubanks, 2018). Moreover, the global nature of AI poses challenges for governance, as regulatory approaches vary across jurisdictions. This fragmentation can lead to regulatory arbitrage, where companies exploit differences in legal frameworks to their advantage (Scherer, 2016). The question of who benefits from the global governance of AI is central to understanding its dynamics. While some argue that governance frameworks can promote fairness and accountability, others contend that they may reinforce existing power imbalances (O'Neil, 2016). As the governance of AI continues to evolve, it is imperative to critically examine the interests and ideas driving these regimes, ensuring that they serve the broader public good rather than narrow corporate or state interests. In conclusion, the global governance of AI is a complex and multifaceted endeavor, characterized by a variety of modalities, rationales, and tensions. As AI technologies continue to advance, it is crucial to develop governance frameworks that are inclusive, transparent, and responsive to the diverse needs and concerns of all stakeholders.", "References": [{"title": "AI4Peopleâ€”An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations", "authors": "Luciano Floridi, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, Effy Vayena", "journal": "Minds and Machines", "year": "2018", "volumes": "28", "first page": "689", "last page": "707", "DOI": "10.1007/s11023-018-9482-5"}, {"title": "Governing Artificial Intelligence: Ethical, Legal and Technical Opportunities and Challenges", "authors": "Corinne Cath", "journal": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences", "year": "2018", "volumes": "376", "first page": "20180080", "last page": "", "DOI": "10.1098/rsta.2018.0080"}, {"title": "The Trouble with Algorithmic Decisions: An Analytic Road Map to Examine Efficiency and Fairness in Automated and Opaque Decision Making", "authors": "Tal Zarsky", "journal": "Science, Technology, & Human Values", "year": "2016", "volumes": "41", "first page": "118", "last page": "132", "DOI": "10.1177/0162243915605575"}, {"title": "Ethical Governance Is Essential to Building Trust in Robotics and Artificial Intelligence Systems", "authors": "Alan Winfield, Marina Jirotka", "journal": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences", "year": "2018", "volumes": "376", "first page": "20180085", "last page": "", "DOI": "10.1098/rsta.2018.0085"}, {"title": "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims", "authors": "Miles Brundage, Shahar Avin, Jasmine Wang, Haydn Belfield, Gretchen Krueger, Gillian Hadfield, Heidy Khlaaf, Jingying Yang, Helen Toner, Ruth Fong", "journal": "arXiv", "year": "2020", "volumes": "", "first page": "", "last page": "", "DOI": "10.48550/arXiv.2004.07213"}, {"title": "Demystifying the Draft EU Artificial Intelligence Act", "authors": "Michael Veale, Frederik Zuiderveen Borgesius", "journal": "Computer Law & Security Review", "year": "2018", "volumes": "34", "first page": "722", "last page": "723", "DOI": "10.1016/j.clsr.2018.08.002"}, {"title": "Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor", "authors": "Virginia Eubanks", "journal": "", "year": "2018", "volumes": "", "first page": "", "last page": "", "DOI": ""}, {"title": "Regulating Artificial Intelligence Systems: Risks, Challenges, Competencies, and Strategies", "authors": "Matthew U. Scherer", "journal": "Harvard Journal of Law & Technology", "year": "2016", "volumes": "29", "first page": "353", "last page": "400", "DOI": ""}, {"title": "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy", "authors": "Cathy O'Neil", "journal": "", "year": "2016", "volumes": "", "first page": "", "last page": "", "DOI": ""}]}