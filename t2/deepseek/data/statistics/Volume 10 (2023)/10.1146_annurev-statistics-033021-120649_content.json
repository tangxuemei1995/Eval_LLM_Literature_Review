{"Abstract": "The integration of machine learning algorithms into risk assessment within the criminal justice system has raised significant concerns regarding fairness and discrimination. This study explores the development of fair risk algorithms that mitigate bias while maintaining predictive accuracy. By leveraging optimal transport theory, we propose a novel framework that ensures equitable treatment across different demographic groups. Our approach focuses on conformation prediction, a critical aspect of risk assessment, to balance the trade-off between fairness and efficiency. Through extensive empirical analysis, we demonstrate that our method significantly reduces discriminatory outcomes without compromising the algorithm's performance. This research contributes to the ongoing discourse on ethical AI by providing a scalable solution for implementing fair risk assessment tools in the criminal justice system, thereby promoting justice and equality in algorithmic decision-making processes."}