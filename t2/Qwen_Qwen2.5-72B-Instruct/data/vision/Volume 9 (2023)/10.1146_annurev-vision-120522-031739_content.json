{"Abstract": "This study investigates the adequacy of deep neural networks (DNNs) as models of human visual perception, focusing on object recognition tasks. By comparing the performance of state-of-the-art DNNs with human psychophysical data, we assess the extent to which these computational models can replicate human visual processing. Our analysis reveals that while DNNs exhibit remarkable accuracy in object recognition, they often fail to capture the nuanced and context-dependent aspects of human perception. Specifically, DNNs show discrepancies in their sensitivity to visual features and their robustness to image transformations, suggesting that current models may not fully account for the complexity of human visual processing. These findings highlight the need for more sophisticated computational models that integrate higher-level cognitive processes and dynamic, context-sensitive mechanisms to better align with human visual behavior."}