{"grounding": "Interpreting anaphoric references is a fundamental aspect of our language competence that has long attracted the attention of computational linguists. The appearance of ever-larger anaphorically annotated data sets covering more and more anaphoric phenomena in ever-greater detail has spurred the development of increasingly more sophisticated computational models; as a result, the most recent state-of-the-art neural models are able to achieve impressive performance by leveraging linguistic, lexical, discourse, and encyclopedic information. This article provides a thorough survey of anaphora resolution (coreference) throughout this development, reviewing the available data sets and covering both the preneural history of the field and\u2014in more detail\u2014current neural models, including research on less-studied aspects of anaphoric interpretation such as bridging reference resolution and discourse deixis interpretation.", "generated_text": "This study explores computational models of anaphora, focusing on anaphora resolution and coreference within natural language processing. We examine various corpora designed for anaphora tasks, highlighting their role in training and evaluating models. The paper delves into neural models for coreference, emphasizing advancements in deep learning techniques that enhance resolution accuracy. Additionally, we address bridging reference and discourse deixis, discussing their implications for understanding complex linguistic structures. The Winograd Schema Challenge is analyzed as a benchmark for evaluating model performance in resolving ambiguous references. Our findings suggest that integrating diverse linguistic features and context-aware mechanisms significantly improves anaphora resolution, paving the way for more sophisticated discourse analysis in computational linguistics.", "label": 1}