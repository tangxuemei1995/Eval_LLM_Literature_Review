{"grounding": "Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.", "generated_text": "The integration of artificial intelligence (AI) into government operations presents both opportunities and challenges, necessitating a nuanced approach to regulation and sociotechnical design. This study explores the complexities involved in regulating AI within public administration, emphasizing the need for a framework that balances innovation with ethical considerations and public accountability. By examining current regulatory practices and institutional designs, the research identifies key areas where AI can enhance governmental efficiency and transparency, while also highlighting potential risks such as bias, privacy concerns, and the erosion of public trust. The paper argues for a collaborative approach to AI governance, involving stakeholders from various sectors to ensure that AI systems are designed and implemented in a manner that aligns with democratic values and societal needs. Through a comprehensive analysis of case studies and policy frameworks, the study provides insights into effective strategies for managing the sociotechnical challenges posed by AI in government, ultimately advocating for adaptive regulatory mechanisms that can evolve alongside technological advancements.", "label": 1}