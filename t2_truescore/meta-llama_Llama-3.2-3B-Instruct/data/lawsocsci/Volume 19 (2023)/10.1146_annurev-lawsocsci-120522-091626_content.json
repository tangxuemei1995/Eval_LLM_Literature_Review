{"grounding": "Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.", "generated_text": "The integration of artificial intelligence (AI) into government public administration poses significant challenges for regulating its development and deployment. This study examines the sociotechnical design of AI systems in government, highlighting the need for a nuanced approach to regulation. Through a mixed-methods analysis of existing literature and case studies, we identify key factors influencing the design of AI systems in government, including institutional capacity, data quality, and stakeholder engagement. Our findings suggest that a sociotechnically informed regulatory framework is essential for ensuring the responsible development and deployment of AI in government. This framework should prioritize transparency, accountability, and human-centered design principles. By adopting a sociotechnical design approach, governments can harness the benefits of AI while mitigating its risks and ensuring that these systems serve the public interest. The implications of our research have significant implications for the development of effective AI regulations in government, and highlight the need for a multidisciplinary approach to addressing the complex challenges of AI governance.", "label": 1}