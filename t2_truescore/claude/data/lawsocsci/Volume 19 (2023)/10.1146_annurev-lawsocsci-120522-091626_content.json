{"grounding": "Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.", "generated_text": "The rapid adoption of artificial intelligence (AI) in government operations presents both opportunities and challenges for public administration. This paper examines the complex task of regulating government AI systems, focusing on the sociotechnical aspects of institutional design. Drawing on literature from public administration, AI ethics, and science and technology studies, we analyze the unique regulatory challenges posed by AI in the public sector. Our findings highlight the need for a multifaceted approach that addresses technical, organizational, and societal dimensions. We argue that effective regulation requires not only technical standards and oversight mechanisms but also careful consideration of organizational structures, decision-making processes, and public engagement. The paper proposes a framework for sociotechnical design in government AI regulation, emphasizing adaptability, transparency, and accountability. By integrating insights from various disciplines, this research contributes to the ongoing debate on responsible AI governance and offers practical recommendations for policymakers and public administrators.", "label": 1}