{"grounding": "Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.", "generated_text": "The integration of Artificial Intelligence (AI) into government operations presents a transformative potential for public administration, offering unprecedented efficiencies and decision-making capabilities. However, this integration also poses significant challenges in terms of regulation and sociotechnical design, necessitating a careful balance between innovation and ethical considerations. This paper explores the complexities of regulating government AI, focusing on the interplay between technological advancements and institutional frameworks. It examines the necessity for adaptive regulatory mechanisms that can accommodate the rapid evolution of AI technologies while ensuring accountability, transparency, and fairness in public administration. The study highlights the importance of a multidisciplinary approach to institutional design, incorporating insights from computer science, law, ethics, and public policy to address the unique challenges posed by AI in government. By analyzing current regulatory practices and proposing a framework for sociotechnical design, this research aims to contribute to the development of robust governance models that can harness the benefits of AI while mitigating its risks, ensuring that government AI serves the public interest effectively and ethically.", "label": 1}