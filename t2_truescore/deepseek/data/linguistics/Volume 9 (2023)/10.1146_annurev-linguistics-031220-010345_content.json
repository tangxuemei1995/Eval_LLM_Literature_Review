{"grounding": "Much has been written on the abuse and misuse of statistical methods, including p values, statistical significance, and so forth. I present some of the best practices in statistics using a running example data analysis. Focusing primarily on frequentist and Bayesian linear mixed models, I illustrate some defensible ways in which statistical inference—specifically, hypothesis testing using Bayes factors versus estimation or uncertainty quantification—can be carried out. The key is to not overstate the evidence and to not expect too much from statistics. Along the way, I demonstrate some powerful ideas, including the use of simulation to understand the design properties of one's experiment before running it, visualization of data before carrying out a formal analysis, and simulation of data from the fitted model to understand the model's behavior.", "generated_text": "This paper explores effective methodologies for analyzing (psycho)linguistic data, emphasizing the integration of experimental linguistics with robust data analysis techniques. We advocate for the adoption of Bayesian methods as a superior framework for hypothesis testing, particularly through the use of Bayes factors, which provide a nuanced measure of evidence for competing hypotheses. Additionally, we highlight the importance of uncertainty quantification in linguistic research, offering strategies to accurately represent and interpret the variability inherent in experimental data. By comparing traditional frequentist approaches with Bayesian alternatives, we demonstrate how the latter can offer more informative and flexible analyses, especially in the context of complex linguistic phenomena. This work aims to guide researchers in selecting appropriate analytical tools that enhance the reliability and interpretability of their findings in the field of (psycho)linguistics.", "label": 1}