{"grounding": "Artificial intelligence (AI) is transforming how governments work, from distribution of public benefits, to identifying enforcement targets, to meting out sanctions. But given AI's twin capacity to cause and cure error, bias, and inequity, there is little consensus about how to regulate its use. This review advances debate by lifting up research at the intersection of computer science, organizational behavior, and law. First, pushing past the usual catalogs of algorithmic harms and benefits, we argue that what makes government AI most concerning is its steady advance into discretion-laden policy spaces where we have long tolerated less-than-full legal accountability. The challenge is how, but also whether, to fortify existing public law paradigms without hamstringing government or stymieing useful innovation. Second, we argue that sound regulation must connect emerging knowledge about internal agency practices in designing and implementing AI systems to longer-standing lessons about the limits of external legal constraints in inducing organizations to adopt desired practices. Meaningful accountability requires a more robust understanding of organizational behavior and law as AI permeates bureaucratic routines.", "generated_text": "This paper explores the challenges and opportunities in regulating artificial intelligence (AI) within government contexts, focusing on the sociotechnical dimensions of institutional design. As governments increasingly adopt AI to enhance decision-making and service delivery, the need for robust regulatory frameworks becomes paramount. The paper examines how public administration can navigate the complexities of AI, ensuring that technological advancements align with ethical, legal, and social standards. Through a review of existing literature and case studies, the research highlights the importance of interdisciplinary collaboration, stakeholder engagement, and adaptive governance mechanisms. It argues that effective regulation of government AI requires a nuanced understanding of both technical and social factors, emphasizing the role of institutional design in fostering transparency, accountability, and public trust. The findings suggest that a flexible, participatory approach to regulation can better address the dynamic nature of AI technologies and their impact on public administration.", "label": 1}