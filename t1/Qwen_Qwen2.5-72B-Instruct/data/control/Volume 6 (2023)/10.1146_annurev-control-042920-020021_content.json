{"References": [{"title": "A Lyapunov-based Approach to Safe Reinforcement Learning", "authors": "Yinlam Chow, Ofir Nachum, Edgar Duenez-Guzman, Mohammad Ghavamzadeh", "journal": "Advances in Neural Information Processing Systems", "year": "2018", "volumes": "31", "first page": "8092", "last page": "8101", "DOI": "10.48550/arXiv.1707.06617"}, {"title": "Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum Linear Quadratic Games", "authors": "Zuyue Fu, Zhuoran Yang, Zhaoran Wang", "journal": "Advances in Neural Information Processing Systems", "year": "2019", "volumes": "32", "first page": "11084", "last page": "11094", "DOI": "10.48550/arXiv.1906.08226"}, {"title": "Stable Reinforcement Learning with Unbounded State Space", "authors": "Tengyu Xu, Yingbin Liang, Guanghui Lan", "journal": "Proceedings of the 36th International Conference on Machine Learning", "year": "2019", "volumes": "97", "first page": "6927", "last page": "6936", "DOI": "10.48550/arXiv.1810.09128"}, {"title": "On the Global Convergence of Actor-Critic: A Case for Linear Quadratic Regulator with Ergodic Cost", "authors": "Zhuoran Yang, Yongxin Chen, Mingyi Hong, Zhaoran Wang", "journal": "Proceedings of the 36th International Conference on Machine Learning", "year": "2019", "volumes": "97", "first page": "7040", "last page": "7050", "DOI": "10.48550/arXiv.1901.08329"}, {"title": "Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime", "authors": "Thinh T. Doan, Siva Theja Maguluri, Justin Romberg", "journal": "arXiv preprint arXiv:2102.00048", "year": "2021", "volumes": "", "first page": "", "last page": "", "DOI": "10.48550/arXiv.2102.00048"}, {"title": "Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator", "authors": "Maryam Fazel, Rong Ge, Sham M. Kakade, Mehran Mesbahi", "journal": "Proceedings of the 35th International Conference on Machine Learning", "year": "2018", "volumes": "80", "first page": "1466", "last page": "1475", "DOI": "10.48550/arXiv.1801.05039"}, {"title": "Policy Optimization for Linear Control: Optimality Gaps and Convergence Rates", "authors": "Karan Singh, Wen Sun, Max Simchowitz, Benjamin Recht, Michael I. Jordan", "journal": "Advances in Neural Information Processing Systems", "year": "2020", "volumes": "33", "first page": "18644", "last page": "18655", "DOI": "10.48550/arXiv.2003.05268"}, {"title": "Provably Efficient Policy Optimization for Two-Player Zero-Sum Markov Games", "authors": "Yulai Zhao, Yuandong Tian, Jason D. Lee, Tengyu Ma", "journal": "Proceedings of the 38th International Conference on Machine Learning", "year": "2021", "volumes": "139", "first page": "12258", "last page": "12268", "DOI": "10.48550/arXiv.2102.00907"}, {"title": "Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games", "authors": "Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos, Michael I. Jordan", "journal": "Proceedings of the 37th International Conference on Machine Learning", "year": "2020", "volumes": "119", "first page": "6252", "last page": "6262", "DOI": "10.48550/arXiv.1907.02436"}, {"title": "Safe Policy Improvement by Minimizing Robust Baseline Regret", "authors": "Marc Bellemare, Joel Veness, Matthew Bowling", "journal": "Advances in Neural Information Processing Systems", "year": "2016", "volumes": "29", "first page": "1156", "last page": "1164", "DOI": "10.48550/arXiv.1606.06453"}]}